{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.42108547e-16 4.44089210e-17 4.56856775e-16]\n",
      "[1. 1. 1.]\n",
      "[-0.28034986 -0.65473668  0.42167664]\n",
      "[0.69835876 0.59887862 0.68026069]\n",
      "Training data shape:\n",
      "(50, 2)\n",
      "Testing data shape:\n",
      "(10, 2)\n",
      "\n",
      "normalized training data:\n",
      "[[-0.00635354 -1.13312693]\n",
      " [ 0.7481291  -0.92751508]\n",
      " [ 0.54958103 -0.34494816]\n",
      " [ 0.86725793 -0.75617187]\n",
      " [-0.12548237 -1.30447015]\n",
      " [ 0.39074258 -1.61288793]\n",
      " [-0.64170733 -1.40042235]\n",
      " [-0.99909384 -0.57797492]\n",
      " [-0.91967462 -0.07079902]\n",
      " [-0.36374005 -0.79044051]\n",
      " [-0.68141695  0.3781202 ]\n",
      " [ 0.86725793  1.09433483]\n",
      " [ 1.62174057  2.53361782]\n",
      " [-0.16519199  0.82018569]\n",
      " [-1.03880346  0.1862158 ]\n",
      " [-0.48286889  0.44323062]\n",
      " [ 2.29680397  1.50555854]\n",
      " [-0.04606315 -0.85897779]\n",
      " [ 0.03335607  0.47749926]\n",
      " [ 0.39074258  0.10739793]\n",
      " [ 1.30406367  1.16287212]\n",
      " [-0.99909384 -0.76302559]\n",
      " [-0.5225785  -0.53685255]\n",
      " [-0.48286889 -0.54370628]\n",
      " [-1.31677074 -0.79386737]\n",
      " [-1.43589958 -1.44154472]\n",
      " [ 1.22464444  1.29994669]\n",
      " [ 1.70115979  2.53361782]\n",
      " [ 0.58929065  0.58030519]\n",
      " [ 0.27161375 -0.39292426]\n",
      " [-1.55502842 -0.27641087]\n",
      " [-0.08577276  0.78591705]\n",
      " [ 0.66870987  0.13481284]\n",
      " [-1.59473803 -0.57454806]\n",
      " [ 1.93941746  0.85445433]\n",
      " [ 1.22464444  0.48435299]\n",
      " [ 0.82754832  1.49870481]\n",
      " [-1.03880346 -0.16332435]\n",
      " [-1.19764191 -0.42376603]\n",
      " [-0.60199772  0.58715892]\n",
      " [-0.95938423 -0.12905571]\n",
      " [-0.32403044 -0.15647062]\n",
      " [-0.40344966 -0.44775408]\n",
      " [-1.31677074 -0.2352885 ]\n",
      " [ 0.27161375  1.20056762]\n",
      " [ 0.4304522   1.84824497]\n",
      " [ 0.78783871 -0.50258391]\n",
      " [ 0.23190414 -0.76302559]\n",
      " [ 1.66145018 -1.15368812]\n",
      " [-1.59473803 -1.44154472]]\n",
      "\n",
      "normalized testing data:\n",
      "[[-0.32403044 -1.44839844]\n",
      " [ 0.1127753  -0.40663171]\n",
      " [ 0.35103297 -0.25242282]\n",
      " [-1.27706113  0.06627555]\n",
      " [-0.8402554  -1.29761642]\n",
      " [-0.87996501 -1.41755667]\n",
      " [ 1.06580599  0.18278894]\n",
      " [ 0.23190414 -0.17017808]\n",
      " [-1.03880346 -0.6190973 ]\n",
      " [-0.2049016  -1.1845299 ]]\n",
      "\n",
      "iteration times: 0\n",
      "W: [[ 0.30974978]\n",
      " [-0.64214367]] \n",
      "b: [1.4901161e-08] \n",
      "Train Loss: 0.14044909\n",
      "Test Loss: 0.07361491\n",
      "\n",
      "iteration times: 10000\n",
      "W: [[ 0.9038609]\n",
      " [-1.1211225]] \n",
      "b: [-7.8143785e-09] \n",
      "Train Loss: 5.3749172e-05\n",
      "Test Loss: 0.0018841026\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fed84b6a9781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# evaluate training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing   \n",
    "\n",
    "# Try to find value for W and b to compute y_data = x_data * W + b  \n",
    "\n",
    "# Define dimensions\n",
    "d = 2    # Size of the parameter space\n",
    "N = 50 # Number of data sample\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable(tf.zeros([d, 1], tf.float32), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([1], tf.float32), name=\"biases\")\n",
    "\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32, shape=[None, d])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# hypothesis\n",
    "linear_regression_model = tf.add(tf.matmul(x, W), b)\n",
    "# cost/loss function\n",
    "loss = tf.reduce_mean(tf.square(linear_regression_model - y)) / 2\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 导入训练集和测试集\n",
    "training_filename = \"dataForTraining.txt\"\n",
    "testing_filename = \"dataForTesting.txt\"\n",
    "training_dataset = np.loadtxt(training_filename)\n",
    "testing_dataset = np.loadtxt(testing_filename)\n",
    "dataset = np.vstack((training_dataset,testing_dataset))\n",
    "\n",
    "# 保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据\n",
    "# 特征缩放\n",
    "min_max_scaler = preprocessing.MinMaxScaler() \n",
    "# 标准化\n",
    "normal_scaler = preprocessing.StandardScaler().fit(training_dataset)\n",
    "# 归一化\n",
    "dataset = min_max_scaler.fit_transform(dataset)\n",
    "# 标准化\n",
    "training_dataset = normal_scaler.transform(training_dataset)\n",
    "testing_dataset = normal_scaler.transform(testing_dataset)\n",
    "\n",
    "print(np.mean(training_dataset,axis=0))\n",
    "print(np.std(training_dataset,axis=0))\n",
    "print(np.mean(testing_dataset,axis=0))\n",
    "print(np.std(testing_dataset,axis=0))\n",
    "\n",
    "x_train = np.array(training_dataset[:,:2])\n",
    "y_train = np.array(training_dataset[:,2:3])\n",
    "x_test = np.array(testing_dataset[:,:2])\n",
    "y_test = np.array(testing_dataset[:,2:3])\n",
    "print(\"Training data shape:\")\n",
    "print(x_train.shape)\n",
    "print(\"Testing data shape:\")\n",
    "print(x_test.shape)\n",
    "print('')\n",
    "print(\"normalized training data:\")\n",
    "print(x_train)\n",
    "print('')\n",
    "print(\"normalized testing data:\")\n",
    "print(x_test)\n",
    "print('')\n",
    "\n",
    "save_step_loss = {\"step\":[],\"train_loss\":[],\"test_loss\":[]}# 保存step和loss用于可视化操作\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)  # reset values to wrong\n",
    "    steps = 150001\n",
    "    for i in range(steps):\n",
    "        sess.run(train, {x: x_train, y: y_train})\n",
    "        if i % 10000 == 0:\n",
    "            # evaluate training accuracy\n",
    "            print(\"iteration times: %s\" % i)\n",
    "            curr_W, curr_b, curr_train_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "            print(\"W: %s \\nb: %s \\nTrain Loss: %s\" % (curr_W, curr_b, curr_train_loss))\n",
    "            # Accuracy computation\n",
    "            curr_test_loss = sess.run(loss,{x:x_test,y:y_test})\n",
    "            print(\"Test Loss: %s\\n\" % curr_test_loss)\n",
    "            save_step_loss[\"step\"].append(i)\n",
    "            save_step_loss[\"train_loss\"].append(curr_train_loss)\n",
    "            save_step_loss[\"test_loss\"].append(curr_test_loss)\n",
    "\n",
    "#画图损失函数变化曲线\n",
    "plt.plot(save_step_loss[\"step\"],save_step_loss[\"train_loss\"],label='Training Loss')\n",
    "plt.plot(save_step_loss[\"step\"],save_step_loss[\"test_loss\"],label='Testing Loss')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#画图损失函数变化曲线\n",
    "plt.plot(save_step_loss[\"step\"][1:],save_step_loss[\"train_loss\"][1:],label='Training Loss')\n",
    "plt.plot(save_step_loss[\"step\"][1:],save_step_loss[\"test_loss\"][1:],label='Testing Loss')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#画图损失函数变化曲线\n",
    "plt.plot(save_step_loss[\"step\"][3:],save_step_loss[\"train_loss\"][3:],label='Training Loss')\n",
    "plt.plot(save_step_loss[\"step\"][3:],save_step_loss[\"test_loss\"][3:],label='Testing Loss')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#画图损失函数变化曲线\n",
    "plt.plot(save_step_loss[\"step\"][5:],save_step_loss[\"train_loss\"][5:],label='Training Loss')\n",
    "plt.plot(save_step_loss[\"step\"][5:],save_step_loss[\"test_loss\"][5:],label='Testing Loss')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Train Loss:\\n',save_step_loss[\"train_loss\"])\n",
    "print('')\n",
    "print('Test Loss:\\n',save_step_loss[\"test_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
